self-attention is kind of soft-attention
(key, value) => (x ,x) : weighted_input = x * a
