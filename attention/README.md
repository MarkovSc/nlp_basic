AttentionPytorch.py: soft-attention
AttentionKeras.py: self-attention

self-attention is kind of soft-attention
(key, value) => (x ,x) : weighted_input = x * a
